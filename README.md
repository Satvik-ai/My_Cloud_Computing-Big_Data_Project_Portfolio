# My Cloud Computing - Big Data Project Portfolio

Project Name  | Description 
------------- | -------------
[Stock Anomaly Detection System](https://github.com/Satvik-ai/GCP_Stock_Anomaly_Detection_System) | Real-time stock anomaly detection system using Kafka and Spark Streaming.
[Real-time Image Classification](https://github.com/Satvik-ai/GCP_Real-time_Image_Classification) | A cloud-based real-time image classification pipeline using VMs.
[Decision Tree Classifier Using Spark MLlib](https://github.com/Satvik-ai/GCP_Spark-MLlib) | A decision tree classifier for handwritten digit recognition using Spark's distributed implementation.
[Real-time Row Counter](https://github.com/Satvik-ai/GCP_Real-time_Streaming_Application_Using_Kafka_And_Spark-Streaming) | A real-time streaming application using **Kafka** and **Spark Streaming**.
[Real-time Row Counter 2](https://github.com/Satvik-ai/GCP_Real-time_Count_Lines_Using_Cloud_Functions_Pub-Sub) | Count the number of lines in a file in real-time using **Google Cloud Functions** and **Pub/Sub**.
[SCD Type-II - SparkSQL](https://github.com/Satvik-ai/GCP_SparkSQL_SCD_Type-II) | A SparkSQL code to implement SCD Type II on a customer master data frame.
[SCD Type-II - PySpark](https://github.com/Satvik-ai/GCP_Spark_SCD_Type-II) | A PySpark code to implement SCD Type II on a customer master data frame without using SparkSQL.
[Spark Click Counter](https://github.com/Satvik-ai/GCP_Spark_Count_Clicks) |  A Spark code for finding the number of users clicks between 0-6 hr, 6-12 hr, 12-18 hr, and 18-24 hr using hashing-based methodology.
[Count Lines Using Cloud Functions](https://github.com/Satvik-ai/GCP_Cloud_Functions_Count_Lines) | A Python program to count the lines of a file that is placed in Google Cloud Storage bucket using Google Cloud Functions.
[VM Count Lines](https://github.com/Satvik-ai/GCP_VM_Count_lines) | Deployed a Virtual Machine on GCP and wrote a Python program to count lines of a file placed in GCS bucket.
